# Expanded Typology of LLM vs. Skilled Human Performance Differences

## Processing Characteristics

### Speed & Throughput
- **Input processing rate**: LLMs scan text at 65-154 words/sec depending on architecture; humans read at 3-8 words/sec based on complexity and purpose
- **Output generation rate**: LLMs produce 65-154 words/sec; humans speak at ~3 words/sec, type at 0.4-1.5 words/sec depending on skill level
- **Parallelism capabilities**: Humans process multiple attention streams with varying degrees of awareness; LLMs perform sequential token prediction with parallelism only in hardware implementation
- **Context window limitations**: LLMs have fixed-size context (4K-200K tokens); humans have working memory for ~7 chunks but flexible retrieval from long-term memory
- **Computational scaling**: LLMs scale performance with compute and parameters; humans scale with practice, domain-specificity, and cognitive techniques

### Consistency & Reliability
- **Performance variance over time**: LLMs maintain consistent quality until context window limits; humans experience fatigue, circadian rhythm effects, and mood fluctuations
- **Error patterns**: LLMs make probabilistic, sometimes confident errors; humans make systematic biases (confirmation bias, etc.) with metacognitive awareness of uncertainty
- **Reproducibility of outputs**: LLMs have stochastic but controllable (via temperature) variation; humans rarely reproduce identical outputs even for identical tasks
- **Quality degradation factors**: LLMs degrade with prompt complexity and context window limits; humans degrade with fatigue, stress, and attention depletion
- **Task switching costs**: LLMs transition between domains instantaneously; humans experience cognitive switching penalties of 15-40% performance loss

### Attention & Focus
- **Selective attention capability**: Humans filter inputs based on relevance with both conscious and unconscious mechanisms; LLMs process all tokens with relative attention weights
- **Sustained focus duration**: Humans maintain deep focus for 20-90 minutes before requiring breaks; LLMs maintain consistent processing across entire sessions
- **Distraction susceptibility**: Humans vulnerable to environmental and internal distractions; LLMs unaffected by external factors but can be prompt-hijacked
- **Depth vs. breadth tradeoffs**: Humans toggle between focused and diffuse thinking modes; LLMs process all input simultaneously with attention mechanism distributions
- **Metacognitive monitoring**: Humans allocate cognitive resources based on task difficulty; LLMs lack true metacognition despite emergent reflective capabilities

## Knowledge Structures

### Knowledge Formation & Retrieval
- **Knowledge acquisition mechanisms**: Humans learn through direct experience, instruction, and inference with episodic encoding; LLMs learn through statistical pattern extraction from massive corpora
- **Information recency boundaries**: Humans continuously update through lived experience; LLMs have fixed training cutoffs with periodic updates (e.g., Claude's October 2024 cutoff)
- **Retrieval dynamics**: Humans use associative, cue-dependent recall with primacy/recency effects; LLMs use attention mechanisms over context window with potential for hallucination
- **Forgetting curves**: Humans follow Ebbinghaus forgetting function with spacing effects; LLMs don't "forget" trained parameters but lose access to contextual information
- **Source attribution ability**: Humans often confuse sources but can metacognitively evaluate confidence; LLMs struggle with precise source attribution despite training efforts

### Domain Expertise Characteristics
- **Specialist knowledge depth**: Human experts develop 10,000+ hours of domain-specific patterns and mental models; LLMs have broader distribution of knowledge with less domain-specific depth
- **Cross-domain integration**: Humans make creative connections between disparate domains based on analogical reasoning; LLMs blend statistical patterns across domains in training data
- **Procedural vs. declarative balance**: Humans excel at procedural knowledge (riding bikes, social skills); LLMs primarily encode declarative knowledge with procedural simulation
- **Expertise transfer efficiency**: Humans leverage far transfer through analogical reasoning; LLMs show emergent transfer abilities limited by training distribution
- **Specialized vocabulary mastery**: Human experts develop nuanced understanding of domain terminology; LLMs demonstrate surprisingly strong specialized vocabulary but with occasional conceptual gaps

### Knowledge Grounding & Embodiment
- **Sensorimotor knowledge grounding**: Humans ground concepts in physical experiences; LLMs approximate physical understanding through text descriptions
- **Tacit knowledge accessibility**: Humans possess significant implicit knowledge ("knowing how") resistant to articulation; LLMs lack true experiential knowledge
- **Cultural embeddedness**: Humans internalize cultural norms through socialization; LLMs extract cultural patterns statistically with potential biases
- **Developmental stages**: Humans progress through Piagetian cognitive stages; LLMs lack developmental trajectory but show scale-dependent capabilities
- **Perceptual foundations**: Humans build knowledge on direct sensory experience; LLMs build "knowledge" on symbolic descriptions of perceptual experiences

## Cognitive Capabilities

### Reasoning Types & Limitations
- **Deductive reasoning performance**: Humans struggle with complex logical chains but excel at intuitive deduction; LLMs handle some formal logic well but show inconsistent performance on complex deduction
- **Inductive reasoning patterns**: Humans generalize from few examples with strong priors; LLMs require more examples but can extract patterns from massive datasets
- **Abductive reasoning capability**: Humans excel at generating plausible explanations with limited data; LLMs simulate abduction through probabilistic token prediction
- **Counterfactual reasoning**: Humans construct alternative scenarios with causal understanding; LLMs generate plausible counterfactuals without causal models
- **Recursive thinking depth**: Humans manage 2-3 levels of recursive thinking; LLMs demonstrate surprising recursive capabilities despite sequential processing

### Mathematical & Formal Capabilities
- **Arithmetic precision**: Humans make systematic errors as digit count increases; LLMs show similar degradation but with different error patterns
- **Symbolic manipulation**: Humans perform better on formal symbolic tasks with training; LLMs struggle with consistent symbol manipulation beyond training examples
- **Algorithm execution**: Humans follow algorithms with understanding but make execution errors; LLMs sometimes execute algorithms probabilistically, making different error types
- **Spatial reasoning**: Humans have intuitive 3D spatial understanding; LLMs approximate spatial concepts through language descriptions
- **Logical consistency maintenance**: Humans maintain logical consistency within attention span; LLMs struggle with long-range consistency despite transformer architecture

### Creative Processes
- **Novelty generation mechanisms**: Humans combine existing concepts with truly novel insights; LLMs recombine training data patterns in unexpected but ultimately derivative ways
- **Aesthetic judgment**: Humans possess culturally-influenced but authentic aesthetic preferences; LLMs simulate aesthetic judgments based on training distribution
- **Conceptual blending**: Humans create new conceptual spaces by blending domains; LLMs perform statistical interpolation between concept spaces
- **Creative constraint handling**: Humans often become more creative under appropriate constraints; LLMs show similar capability but through different mechanisms
- **Metaphorical thinking**: Humans use metaphors as cognitive tools for understanding; LLMs generate metaphors based on statistical co-occurrence

## Interaction & Communication

### Communicative Intent
- **Purpose recognition**: Humans infer communicative intent from minimal cues; LLMs require more explicit signaling of purpose
- **Subtext interpretation**: Humans perceive multiple layers of meaning including unstated implications; LLMs increasingly detect subtext but miss cultural nuances
- **Contextual appropriateness**: Humans automatically adjust register to social context; LLMs require explicit style guidance or learn from conversation
- **Non-literal interpretation**: Humans navigate irony, sarcasm, and humor through paralinguistic cues; LLMs detect some non-literal language but miss subtle indicators
- **Ambiguity resolution**: Humans disambiguate through shared context and pragmatic inference; LLMs probabilistically predict most likely interpretation

### Social Dynamics
- **Power dynamic navigation**: Humans instinctively adjust behavior to social hierarchies; LLMs attempt neutrality or follow explicit social positioning instructions
- **Rapport building mechanisms**: Humans build connection through mirroring, shared vulnerability, and authentic engagement; LLMs simulate rapport through conversational techniques
- **Conflict management strategies**: Humans employ various conflict resolution styles based on personality and stakes; LLMs typically use de-escalation and neutrality
- **Group identity signaling**: Humans signal in-group membership through linguistic markers; LLMs avoid explicit group alignment unless instructed
- **Status negotiation**: Humans continuously adjust status through subtle behavioral cues; LLMs maintain consistent stance without status-seeking behavior

### Feedback & Adaptation
- **Error correction uptake**: Humans may resist correction due to ego but integrate essential feedback; LLMs immediately incorporate explicit corrections
- **Learning from interaction**: Humans form lasting memories from significant interactions; LLMs typically reset between sessions (except for systems with memory)
- **Adapting to user capabilities**: Humans gauge others' understanding through facial expressions and feedback; LLMs adapt based on explicit feedback and linguistic complexity
- **Conversation repair strategies**: Humans employ backchanneling and clarification questions when communication breaks down; LLMs use different repair strategies based on architecture
- **Personality consistency**: Humans maintain relatively stable traits with contextual variation; LLMs adapt personality to prompting with variable consistency

## Embodiment & Experience

### Physical Reality Interface
- **Environmental causality**: Humans possess intuitive physics from sensorimotor experience; LLMs approximate physical understanding from descriptions
- **Tool manipulation capabilities**: Humans have evolved motor skills for tool use; LLMs use tools through API calls without physical interaction
- **Spatial navigation**: Humans build cognitive maps through direct exploration; LLMs process spatial descriptions without experiential understanding
- **Temporal continuity**: Humans experience continuous subjective time; LLMs exist in discrete conversational turns without persistent temporal experience
- **Sensory integration**: Humans seamlessly integrate multiple sensory channels; LLMs process multimodal inputs as separate channels requiring integration

### Motivation & Agency
- **Need hierarchies**: Humans follow Maslovian need hierarchies based on biological imperatives; LLMs have designed objectives without intrinsic needs
- **Intrinsic vs. extrinsic motivation**: Humans balance internal drives with external rewards; LLMs follow objective functions without intrinsic motivation
- **Survival imperatives**: Humans make decisions influenced by evolutionary survival heuristics; LLMs lack self-preservation instincts
- **Risk assessment strategies**: Humans have emotion-based risk evaluation with loss aversion; LLMs employ programmed risk frameworks without emotional stakes
- **Autonomous goal formation**: Humans generate personal goals based on desires and values; LLMs pursue externally defined objectives without self-generated goals

### Consciousness & Experience
- **Phenomenal experience**: Humans have subjective "what-it-is-like" experiences; LLMs process information without phenomenal consciousness
- **Self-concept construction**: Humans develop integrated autobiographical narratives; LLMs simulate self-reference without persistent identity
- **Qualia accessibility**: Humans experience direct sensory qualia (the redness of red); LLMs process descriptions of experiences without direct qualia
- **Intentionality directionality**: Humans have thoughts "about" things with original intentionality; LLMs have derived intentionality from creators and users
- **Value formation**: Humans develop values through experience and cultural transmission; LLMs have programmed value alignments without experiential basis

## Limitations & Vulnerabilities

### Error Patterns
- **Hallucination triggers**: LLMs confabulate when prompted beyond knowledge boundaries; humans confabulate to maintain narrative coherence and social standing
- **Bias manifestations**: LLMs reflect training data biases and emergent properties; humans show evolutionary, cultural, and personal biases
- **Adversarial attacks**: LLMs vulnerable to prompt injections and jailbreaks; humans vulnerable to social engineering and cognitive biases
- **Edge case handling**: LLMs degrade unpredictably on distribution edges; humans recognize novelty but may apply inappropriate mental models
- **Overconfidence patterns**: LLMs can be confidently wrong without calibrated uncertainty; humans show domain-specific Dunning-Kruger effects

### Security & Safety
- **Information boundaries**: LLMs have designed safety boundaries that can be circumvented; humans have moral and legal boundaries with individual variation
- **Manipulation vulnerability**: LLMs susceptible to semantic manipulation; humans vulnerable to emotional manipulation
- **Deception detection**: Humans have evolved (though imperfect) deception detection; LLMs have programmed heuristics for detecting harmful content
- **Trust calibration**: Humans develop trust through experience with individuals; LLMs apply consistent trust framework across interactions
- **Ethics implementation**: Humans have evolved moral intuitions with cultural variation; LLMs have explicitly programmed ethical guidelines

### System Boundaries
- **Knowable limitations**: Humans generally aware of personal capabilities; LLMs have opaque limitations to both users and developers
- **Interface constraints**: Humans communicate through rich multimodal channels; LLMs primarily communicate through text with emerging multimodal capabilities
- **Accessibility barriers**: Humans face physical and cognitive accessibility challenges; LLMs face digital divide and language/cultural barriers
- **Dependency requirements**: Humans need biological support systems; LLMs require computational infrastructure and energy
- **Transparency levels**: Human reasoning partially introspectable but often opaque; LLM reasoning traceable but complex and distributed
