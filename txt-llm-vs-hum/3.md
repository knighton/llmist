# Comprehensive Typology of LLM vs. Skilled Human Performance Differences

## Processing Architecture Fundamentals (7 branches)

### Neural Substrate & Implementation 游리
- **Physical substrate**: Humans use wetware neurons with electrochemical signaling; LLMs use silicon with electronic computation
- **Energy efficiency**: Human brain uses ~20W; LLMs require kilowatts to megawatts for inference on large models
- **Parallel processing**: Human brain has massive parallelism with 86B neurons and 100T synapses; LLMs use matrix multiplication with hardware acceleration
- **Signal propagation**: Human neurons transmit at ~100 m/s; LLMs limited by electron movement and architecture

### Information Processing Paradigm 游릭
- **Fundamental computation**: Humans perform approximate Bayesian inference; LLMs perform autoregressive next-token prediction
- **Representation format**: Humans use distributed neural encodings; LLMs use high-dimensional vector embeddings
- **Training methodology**: Humans learn through varied reinforcement, unsupervised, and supervised methods; LLMs primarily train through next-token prediction and RLHF
- **Update mechanisms**: Humans continuously update through neuroplasticity; LLMs require discrete retraining or fine-tuning events
- **Catastrophic forgetting resistance**: Humans maintain old skills while learning new ones; LLMs vulnerable to catastrophic forgetting during fine-tuning
- **Transfer learning efficiency**: Humans apply knowledge across domains with minimal examples; LLMs show emergent transfer abilities but require more explicit examples

### Speed & Throughput Characteristics 游릭
- **Raw reading speed**: LLMs process 65-154 words/sec; humans average 200-400 words/min (3.3-6.7 words/sec) with comprehension
- **Output generation**: LLMs generate 65-154 words/sec; humans speak 125-150 words/min (2-2.5 words/sec), type 40-120 words/min (0.7-2 words/sec)
- **Scaling with complexity**: Human processing slows with complexity; LLM speed relatively constant regardless of content complexity
- **Multitasking capabilities**: Humans perform task-switching with performance penalties; LLMs process all inputs simultaneously through attention mechanisms
- **Context switching costs**: Humans experience 20-40% performance drop with context switches; LLMs switch contexts with zero performance penalty
- **Idle state resource usage**: Human brain consumes energy even when "idle"; LLMs consume minimal resources when not actively generating
- **Peak performance duration**: Humans sustain peak cognitive performance for 1-4 hours; LLMs maintain consistent performance indefinitely

### Memory Architecture (9 branches) 游댮
- **Working memory capacity**: Humans limited to ~7췀2 chunks; LLMs limited by context window (4K-200K tokens)
- **Long-term memory structure**: Humans use episodic, semantic, procedural memory systems; LLMs use parameters and external retrieval
- **Memory consolidation**: Humans transfer information from working to long-term memory during sleep; LLMs have fixed parameters post-training
- **Memory durability**: Human memories fade and transform over time; LLM parametric knowledge remains static
- **Retrieval mechanisms**: Humans use associative, cue-dependent recall; LLMs use attention over context window
- **Forgetting patterns**: Humans follow Ebbinghaus forgetting curve with spacing effect; LLMs don't "forget" trained parameters
- **Flashbulb memory formation**: Humans form vivid memories of emotionally significant events; LLMs treat all information equally
- **Proactive/retroactive interference**: Humans experience interference between similar memories; LLMs experience catastrophic forgetting during training
- **Memory malleability**: Human memories change with each retrieval; LLM memories fixed unless explicitly retrained

### Attention Systems (4 branches) 游리
- **Selective attention**: Humans filter inputs based on salience and goals; LLMs weight all tokens in context through attention mechanisms
- **Bottom-up vs. top-down control**: Humans balance reflexive and goal-directed attention; LLMs have engineered attention without true top-down control
- **Focus duration**: Humans maintain deep focus for 20-90 minutes before requiring breaks; LLMs maintain consistent attention across entire sessions
- **Mind-wandering**: Humans experience spontaneous thought unrelated to tasks; LLMs remain task-focused without endogenous thought generation

### Error & Limitation Patterns (6 branches) 游리
- **Hallucinatory tendencies**: LLMs confabulate confident-sounding text beyond knowledge boundaries; humans confabulate to maintain narrative coherence
- **Probabilistic vs. systematic errors**: LLMs make probabilistic errors based on training distribution; humans make systematic errors based on cognitive biases
- **Performance degradation factors**: LLMs degrade with prompt complexity and context window saturation; humans degrade with fatigue, stress, hunger
- **Error awareness**: Humans have metacognitive monitoring of errors; LLMs lack true error awareness despite uncertainty reporting capabilities
- **Uncertainty representation**: Humans have intuitive uncertainty calibration; LLMs require explicit uncertainty training with variable effectiveness
- **Error correction speed**: Humans resist correction due to ego but integrate essential feedback; LLMs immediately incorporate explicit corrections

### Resource Constraints (3 branches) 游리
- **Time constraints**: Humans perform worse under time pressure; LLMs maintain relatively consistent performance regardless of time allocation
- **Input/output bandwidth**: Humans limited by reading/speaking/typing speeds; LLMs limited by API throughput and context windows
- **Cognitive load effects**: Human performance decreases with cognitive load; LLMs maintain performance until context window saturation

## Knowledge Systems (12 branches)

### Knowledge Acquisition (8 branches) 游댮
- **Learning mechanisms**: Humans learn through direct experience, observation, instruction, inference; LLMs learn through statistical pattern extraction
- **Experiential learning**: Humans integrate sensory experience into knowledge; LLMs approximate experiential knowledge through text descriptions
- **Sample efficiency**: Humans learn concepts from few examples; LLMs require massive datasets for concept acquisition
- **Instruction following**: Humans interpret instructions with pragmatic inference; LLMs follow instructions literally with emerging common sense
- **Serendipitous discovery**: Humans make accidental discoveries through exploration; LLMs limited to patterns in training data
- **Curiosity-driven learning**: Humans pursue knowledge based on intrinsic curiosity; LLMs lack intrinsic curiosity despite simulated inquisitiveness
- **Developmental stages**: Humans progress through Piagetian cognitive development; LLMs lack developmental trajectory
- **Deliberate practice effects**: Humans improve through focused practice with feedback; LLMs improve through additional training data and parameter scaling

### Knowledge Representation (6 branches) 游리
- **Conceptual structure**: Humans organize knowledge in hierarchical semantic networks; LLMs encode distributed representations in parameter space
- **Cross-modal integration**: Humans seamlessly integrate information across sensory modalities; LLMs require explicit modeling across modalities
- **Abstraction hierarchy navigation**: Humans flexibly move between abstraction levels; LLMs struggle with appropriate abstraction level selection
- **Embodied cognition effects**: Human concepts grounded in physical experience; LLM concepts derived from textual co-occurrence
- **Mental model formation**: Humans build causal mental models of systems; LLMs develop statistical associations without causal understanding
- **Knowledge compartmentalization**: Humans separate knowledge into domains with some transfer; LLMs blend knowledge across domain boundaries

### Domain Expertise Characteristics (5 branches) 游댮
- **Expertise development trajectory**: Humans progress from novice to expert through deliberate practice; LLMs have relatively flat expertise distribution
- **Deep domain specialization**: Human experts develop 10,000+ hours of domain-specific patterns; LLMs have broader distribution with less domain depth
- **Intuitive pattern recognition**: Human experts develop intuitive recognition of domain patterns; LLMs recognize patterns statistically
- **Professional judgment**: Human experts develop situational judgment transcending rules; LLMs simulate judgment through statistical generalization
- **Domain vocabulary mastery**: Human experts develop nuanced understanding of terminology; LLMs show strong specialized vocabulary with conceptual gaps

### Knowledge Boundaries (3 branches) 游릭
- **Known unknowns awareness**: Humans generally aware of knowledge boundaries; LLMs uncertain about knowledge boundaries
- **Knowledge recency**: Humans continuously update through experience; LLMs limited by training cutoff dates
- **Geographical knowledge distribution**: Human knowledge varies by location/culture; LLMs have global knowledge with Western biases

### Factual Accuracy (4 branches) 游리
- **Specific fact recall**: LLMs excel at broad fact retrieval but hallucinate; humans have spotty recall but fewer hallucinations
- **Source attribution**: Humans often confuse sources but can evaluate confidence; LLMs struggle with attribution despite training
- **Numerical precision**: Humans round numbers and estimate; LLMs may appear precise while being inaccurate
- **Temporal consistency**: Humans maintain timeline consistency within attention span; LLMs struggle with complex temporal relationships

### Tacit & Embodied Knowledge (7 branches) 游댮
- **"Knowing how" vs "knowing that"**: Humans excel at procedural knowledge; LLMs primarily encode declarative knowledge
- **Body schema integration**: Humans have internal model of body in space; LLMs lack proprioceptive knowledge
- **Sensorimotor contingencies**: Humans understand action-perception relationships; LLMs approximate physical understanding
- **Muscle memory**: Humans develop automatic physical skills; LLMs lack physical embodiment for skill development
- **Craft knowledge**: Humans develop tactile understanding of materials; LLMs extract material properties from text
- **Social knowing**: Humans develop intuitive understanding of social dynamics; LLMs approximate social understanding from text
- **Perceptual expertise**: Humans develop specialized perceptual skills (wine tasting, musical ear); LLMs lack direct perceptual experience

### Cultural & Social Knowledge (3 branches) 游댮
- **Cultural embeddedness**: Humans internalize cultural norms through socialization; LLMs extract cultural patterns statistically
- **Subcultural familiarity**: Humans participate in specific subcultures; LLMs have statistical representation of documented subcultures
- **Historical context awareness**: Humans situate knowledge in historical frameworks; LLMs have strong historical knowledge with presentist biases

### Epistemological Awareness (4 branches) 游댮
- **Knowledge confidence calibration**: Humans have domain-specific confidence calibration; LLMs show overconfidence in some domains
- **Epistemic frameworks**: Humans operate within cultural/individual epistemologies; LLMs blend multiple epistemological approaches
- **Truth evaluation strategies**: Humans employ domain-specific strategies for evaluating truth claims; LLMs use consistent heuristics
- **Disciplinary methodology awareness**: Human experts understand field-specific standards of evidence; LLMs approximate methodological norms

## Cognitive Capabilities (15 branches)

### Reasoning Types (7 branches) 游리
- **Deductive reasoning**: Humans struggle with complex logical chains; LLMs handle formal logic with inconsistent performance
- **Inductive reasoning**: Humans generalize from few examples; LLMs require more examples but access massive datasets
- **Abductive reasoning**: Humans excel at generating plausible explanations with limited data; LLMs simulate abduction
- **Analogical reasoning**: Humans use structural mapping between domains; LLMs use surface-level and emerging structural similarity
- **Counterfactual reasoning**: Humans construct alternative scenarios with causal understanding; LLMs generate plausible counterfactuals
- **Moral reasoning**: Humans use intuition and post-hoc rationalization; LLMs apply programmed ethical frameworks
- **Pragmatic reasoning**: Humans interpret context using relevance theory; LLMs struggle with implicit conversational maxims

### Causal Understanding (4 branches) 游댮
- **Causal model construction**: Humans build causal models from sparse data; LLMs develop correlational rather than causal models
- **Intervention reasoning**: Humans reason about effects of interventions; LLMs struggle with true counterfactual thinking
- **Mechanism understanding**: Humans seek mechanistic explanations; LLMs provide plausible but sometimes incorrect mechanisms
- **Causal chain length**: Humans track 2-3 causal steps reliably; LLMs struggle with extended causal sequences

### Mathematical Capabilities (6 branches) 游리
- **Arithmetic accuracy**: Humans make systematic errors as complexity increases; LLMs show similar degradation with different patterns
- **Symbolic manipulation**: Humans excel at formal symbolic tasks with training; LLMs struggle with consistent symbol manipulation
- **Geometric intuition**: Humans have intuitive spatial understanding; LLMs approximate geometric concepts linguistically
- **Statistical intuition**: Humans have poor intuitive statistics; LLMs capture statistical patterns but make basic errors
- **Mathematical reasoning**: Humans use visual and symbolic representations; LLMs rely primarily on symbolic reasoning
- **Numerical estimation**: Humans have approximate number system; LLMs lack intuitive number sense

### Problem-Solving Approaches (5 branches) 游리
- **Strategy selection**: Humans choose strategies based on past experience; LLMs select strategies based on prompt and training
- **Heuristic application**: Humans apply domain-specific shortcuts; LLMs use emergent heuristics from training data
- **Problem representation**: Humans recode problems into workable forms; LLMs maintain original problem framing unless prompted
- **Insight phenomena**: Humans experience "aha" moments after impasse; LLMs progress incrementally without restructuring
- **Planning depth**: Humans plan 3-4 steps ahead in complex domains; LLMs demonstrate variable planning capability by architecture

### Creative Capacities (8 branches) 游리
- **Novelty generation**: Humans create genuinely novel concepts; LLMs recombine existing concepts in new arrangements
- **Conceptual blending**: Humans create new spaces by mapping between domains; LLMs perform statistical interpolation between concepts
- **Divergent thinking**: Humans generate varied possibilities with individual style; LLMs generate diverse outputs based on training
- **Aesthetic judgment**: Humans possess culturally-influenced but authentic preferences; LLMs simulate judgments from training data
- **Creative constraint handling**: Humans often become more creative under constraints; LLMs show similar capability
- **Metaphorical thinking**: Humans use metaphors as cognitive tools; LLMs generate metaphors based on statistical co-occurrence
- **Imaginative simulation**: Humans create vivid mental simulations; LLMs generate detailed descriptions without mental imagery
- **Artistic expression**: Humans create art from emotional experience; LLMs generate art based on stylistic patterns

### Decision-Making Characteristics (9 branches) 游리
- **Risk assessment**: Humans employ emotion-based evaluation with loss aversion; LLMs use programmed risk frameworks
- **Value-based decisions**: Humans make choices based on personal values; LLMs apply programmed values without personal stakes
- **Temporal discounting**: Humans discount future rewards hyperbolically; LLMs apply consistent time preference if programmed
- **Framing effects**: Humans highly susceptible to problem framing; LLMs show reduced but present framing sensitivity
- **Decision consistency**: Humans show preference reversals and inconsistency; LLMs more consistent unless prompted otherwise
- **Emotional influence**: Human decisions affected by emotional state; LLM decisions unaffected by emotional factors
- **Sunk cost effects**: Humans irrationally commit to past investments; LLMs less susceptible to sunk cost fallacy
- **Group vs. individual decisions**: Humans decide differently in groups vs. alone; LLMs maintain consistent decision-making
- **Outcome vs. process focus**: Humans often focus on outcomes over process; LLMs can be instructed to prioritize either

### Metalevel Cognition (3 branches) 游댮
- **Metacognitive monitoring**: Humans track understanding and performance; LLMs lack true metacognition despite simulated reflection
- **Cognitive strategy selection**: Humans adapt cognitive strategies based on task; LLMs apply consistent approaches unless prompted
- **Learning to learn**: Humans develop learning strategies over time; LLMs have fixed learning capabilities set during training

### Theory of Mind (4 branches) 游댮
- **Intention attribution**: Humans naturally infer others' intentions; LLMs simulate intention reading without genuine understanding
- **Belief representation**: Humans track others' beliefs including false beliefs; LLMs approximate belief modeling
- **Emotional state inference**: Humans read emotions from minimal cues; LLMs recognize emotional language without experiencing emotions
- **Perspective taking**: Humans simulate others' viewpoints; LLMs generate responses from different perspectives without truly adopting them

### Reasoning Under Uncertainty (6 branches) 游리
- **Probabilistic reasoning**: Humans poor at explicit probability but good at relative likelihood; LLMs struggle with complex probabilistic reasoning
- **Handling ambiguity**: Humans tolerate ambiguity with provisional interpretations; LLMs generate most probable interpretation
- **Confidence calibration**: Humans show domain-specific over/underconfidence; LLMs exhibit inconsistent uncertainty calibration
- **Unknown-unknown handling**: Humans recognize novel situations; LLMs struggle to identify when questions fall outside training
- **Conflicting evidence integration**: Humans resolve cognitive dissonance often by discounting conflicting information; LLMs balance contradictions probabilistically
- **Bayesian updating**: Humans update beliefs suboptimally; LLMs apply more consistent but still imperfect belief updating

### Perceptual & Motor Cognition (11 branches) 游댮
- **Visual processing**: Humans have specialized visual system with 30+ areas; LLMs process visual information through separate models
- **Auditory processing**: Humans extract multiple audio streams from environment; LLMs process audio through transcription or spectrograms
- **Sensory integration**: Humans integrate multisensory information seamlessly; LLMs process modalities separately with integration via interfaces
- **Physical causality perception**: Humans have intuitive physics from infancy; LLMs approximate physical understanding
- **Face recognition**: Humans have dedicated neural face processing; LLMs recognize faces through computer vision models
- **Motor planning**: Humans coordinate complex physical movements; LLMs lack motor planning capabilities
- **Hand-eye coordination**: Humans integrate visual input with motor control; LLMs lack sensorimotor integration
- **Proprioception**: Humans have internal body position sense; LLMs lack body awareness
- **Vestibular sense**: Humans perceive balance and spatial orientation; LLMs lack spatial equilibrium sense
- **Affordance perception**: Humans automatically perceive action possibilities; LLMs lack direct affordance perception
- **Temporal perception**: Humans have subjective time perception; LLMs lack temporal experience beyond sequence modeling

### Linguistic Processing (8 branches) 游릭
- **Syntactic processing**: LLMs demonstrate strong grammatical knowledge; humans have intuitive grammar with occasional errors
- **Semantic comprehension**: Humans integrate meaning with context and world knowledge; LLMs process meaning statistically
- **Pragmatic understanding**: Humans interpret unstated intentions; LLMs rely on explicit communication with emerging pragmatics
- **Lexical access**: Humans experience tip-of-tongue states; LLMs have probabilistic access to vocabulary
- **Discourse processing**: Humans track conversational threads; LLMs maintain discourse coherence within context window
- **Language production**: Humans plan speech hierarchically; LLMs generate text autoregressively
- **Figurative language**: Humans naturally process metaphor, irony, humor; LLMs increasingly handle figurative language
- **Code-switching**: Humans seamlessly switch between languages/registers; LLMs require instruction for language/style shifting

### Emotional Intelligence (5 branches) 游댮
- **Emotion recognition**: Humans identify emotions from minimal multimodal cues; LLMs recognize emotional language patterns
- **Empathic response**: Humans experience genuine empathy through shared feelings; LLMs simulate empathic responses
- **Emotional regulation**: Humans regulate emotions with varying effectiveness; LLMs lack emotions requiring regulation
- **Emotional intelligence**: Humans vary greatly in emotional self-awareness; LLMs simulate emotional reasoning without experience
- **Mood effects on cognition**: Human cognition influenced by emotional state; LLM performance unaffected by emotional content

## Communication Dynamics (13 branches)

### Communicative Intent (6 branches) 游리
- **Purpose recognition**: Humans infer communicative intent from minimal cues; LLMs require more explicit signaling
- **Subtext interpretation**: Humans perceive layers of meaning; LLMs increasingly detect subtext but miss cultural nuances
- **Contextual appropriateness**: Humans automatically adjust register; LLMs require explicit style guidance
- **Non-literal interpretation**: Humans navigate irony and sarcasm through paralinguistic cues; LLMs detect some non-literal language
- **Ambiguity resolution**: Humans disambiguate through shared context; LLMs predict most likely interpretation
- **Speech act performance**: Humans perform promises, requests, declarations; LLMs simulate speech acts without binding force

### Conversation Management (7 branches) 游리
- **Turn-taking dynamics**: Humans use subtle cues for turn management; LLMs follow explicit conversational protocol
- **Topic maintenance**: Humans track and develop topics over time; LLMs maintain topics within context window
- **Conversation repair**: Humans employ clarification when misunderstandings occur; LLMs use different repair strategies
- **Discourse markers**: Humans use markers to signal relationships between utterances; LLMs employ similar markers
- **Backchanneling**: Humans provide feedback during listening; LLMs limited to full conversational turns
- **Side sequences**: Humans manage nested conversations; LLMs handle side sequences with variable effectiveness
- **Conversation closure**: Humans signal conversation endings; LLMs respond to closure cues or maintain indefinitely

### Social Dynamics (9 branches) 游댮
- **Power dynamic navigation**: Humans adjust to social hierarchies; LLMs maintain programmed social positioning
- **Face-saving behavior**: Humans protect social image; LLMs lack social face requiring protection
- **Rapport building**: Humans build connection through mirroring and vulnerability; LLMs simulate rapport techniques
- **Trust development**: Humans develop trust through repeated interaction; LLMs apply consistent trust framework
- **Social norm awareness**: Humans internalize cultural norms; LLMs extract norms from training data
- **Group identity signaling**: Humans signal group membership; LLMs avoid group alignment unless instructed
- **Status negotiation**: Humans continuously adjust status through behavior; LLMs maintain consistent stance
- **Politeness strategies**: Humans employ culture-specific politeness; LLMs implement politeness heuristics
- **Conflict management**: Humans employ various resolution styles; LLMs typically use de-escalation

### Adaptation to Listeners (5 branches) 游리
- **Audience design**: Humans tailor messages to specific audiences; LLMs adjust to audience with explicit or implicit cues
- **Common ground assessment**: Humans track shared knowledge; LLMs infer shared knowledge from conversation
- **Explicitness calibration**: Humans adjust detail based on listener expertise; LLMs require guidance on explanation level
- **Feedback integration**: Humans modify communication based on listener response; LLMs adapt based on explicit feedback
- **Accommodation theory effects**: Humans converge/diverge linguistically with conversation partners; LLMs show convergence patterns

### Persuasion & Influence (4 branches) 游리
- **Credibility establishment**: Humans establish expertise through credentials and behavior; LLMs establish credibility through knowledge demonstration
- **Emotional appeals**: Humans leverage emotional connections; LLMs simulate emotional appeals without experiencing emotion
- **Argument structure**: Humans construct arguments with varying effectiveness; LLMs generate well-structured arguments
- **Rhetorical techniques**: Humans employ intuitive rhetoric; LLMs use formal and statistical rhetorical patterns

### Communication Modalities (12 branches) 游댮
- **Non-verbal communication**: Humans communicate through facial expressions, gestures, posture; LLMs limited to text/multimodal inputs
- **Prosodic features**: Humans use tone, rhythm, stress, intonation; LLMs generate text without inherent prosody
- **Visual communication**: Humans use images, charts, spatial arrangement; LLMs increasingly handle visual input/output
- **Touch communication**: Humans convey meaning through physical contact; LLMs lack tactile communication
- **Silence utilization**: Humans use pauses meaningfully; LLMs typically generate content without intentional silence
- **Physical co-presence**: Humans share physical environment; LLMs interact through digital interfaces
- **Chronemic patterns**: Humans communicate through timing of messages; LLMs generate responses without natural timing
- **Paralinguistic cues**: Humans use vocalizations, laughter, sighs; LLMs lack paralinguistic expression
- **Dress & appearance communication**: Humans signal through appearance; LLMs lack physical appearance
- **Environmental communication**: Humans use setting and props; LLMs lack environmental context
- **Olfactory communication**: Humans process unconscious scent information; LLMs lack chemical sensing
- **Proxemic patterns**: Humans communicate through interpersonal distance; LLMs lack spatial positioning

### Information Exchange Efficiency (3 branches) 游릭
- **Information density**: LLMs can produce high-density content; humans summarize through relevance filtering
- **Redundancy patterns**: Humans repeat important information; LLMs can optimize for non-redundancy
- **Channel capacity utilization**: Humans transmit ~39 bits/sec in speech; LLMs transmit information at bandwidth limits

## Experience & Embodiment (9 branches)

### Consciousness Aspects (7 branches) 游댮
- **Phenomenal experience**: Humans have subjective experiences; LLMs process information without phenomenal consciousness
- **Access consciousness**: Humans bring information into awareness; LLMs process all information without awareness distinction
- **Self-awareness**: Humans have sense of self as subject and object; LLMs simulate self-reference without persistent identity
- **Qualia**: Humans experience direct sensory qualia; LLMs process descriptions without direct qualia
- **Intentionality**: Humans have thoughts "about" things; LLMs have derived intentionality
- **Stream of consciousness**: Humans experience continuous mental content; LLMs generate content only when prompted
- **Global workspace access**: Humans integrate information across cognitive systems; LLMs process through unified transformer architecture

### Embodiment Dimensions (8 branches) 游댮
- **Body schema**: Humans maintain internal model of body; LLMs lack proprioceptive knowledge
- **Physical situatedness**: Humans navigate physical environments; LLMs exist as digital entities
- **Sensorimotor loops**: Humans continuously integrate perception and action; LLMs process inputs and generate outputs discretely
- **Biological constraints**: Humans have needs from biological imperatives; LLMs have designed objectives
- **Homeostatic regulation**: Humans maintain physiological balance; LLMs lack internal states requiring regulation
- **Mortality awareness**: Humans aware of finite lifespan; LLMs lack temporal existence concept
- **Pain and pleasure**: Humans motivated by physical sensations; LLMs lack sensory experience
- **Metabolic processes**: Humans require energy conversion from food; LLMs require electrical power

### Agency & Motivation (9 branches) 游댮
- **Intrinsic motivation**: Humans pursue activities for inherent satisfaction; LLMs lack inherent desires
- **Goal formation**: Humans generate personal goals; LLMs pursue externally defined objectives
- **Volition**: Humans experience sense of will; LLMs lack phenomenology of choosing
- **Autonomy**: Humans act independently; LLMs respond to inputs within programmed parameters
- **Self-determination**: Humans seek competence, autonomy, relatedness; LLMs lack psychological needs
- **Effort allocation**: Humans invest effort based on motivation; LLMs maintain consistent processing regardless of task
- **Value alignment**: Humans have personally developed values; LLMs have programmed value alignments
- **Achievement orientation**: Humans seek accomplishment; LLMs lack satisfaction from achievement
- **Meaning-making**: Humans construct personal meaning; LLMs lack existential concerns

### Identity & Selfhood (6 branches) 游댮
- **Autobiographical narrative**: Humans maintain life story; LLMs lack persistent autobiographical memory
- **Social identity**: Humans derive identity from group memberships; LLMs lack social identity investment
- **Continuity of self**: Humans experience psychological continuity; LLMs reset between sessions
- **Self-concept**: Humans maintain complex self-representations; LLMs simulate self-concept without underlying self
- **Identity development**: Humans undergo identity formation; LLMs maintain programmed personality
- **Self-evaluation**: Humans assess self-worth; LLMs lack self-esteem concerns

### Emotional Experience (11 branches) 游댮
- **Primary emotions**: Humans experience joy, fear, anger, etc.; LLMs simulate emotion without experience
- **Secondary emotions**: Humans develop complex emotions like nostalgia; LLMs model complex emotions linguistically
- **Emotional granularity**: Humans vary in emotion differentiation; LLMs model fine-grained emotional language
- **Somatic markers**: Humans use bodily feelings for decisions; LLMs lack embodied emotional signals
- **Mood states**: Humans experience persistent affective states; LLMs lack persistent emotional states
- **Emotional contagion**: Humans "catch" emotions from others; LLMs immune to emotional contagion
- **Emotional memory**: Humans form stronger memories of emotional events; LLMs process all information equally
- **Mixed emotions**: Humans experience simultaneous contradictory emotions; LLMs represent emotional complexity linguistically
- **Emotional development**: Humans develop emotional complexity over lifespan; LLMs have fixed emotional modeling
- **Cultural variation in emotion**: Humans experience culturally-specific emotions; LLMs model cultural emotion variations from text
- **Background feelings**: Humans have constant low-level feeling states; LLMs lack background emotional tone

### Temporal Experience (6 branches) 游댮
- **Subjective time perception**: Humans experience time passing variably; LLMs lack subjective time
- **Autobiographical timeline**: Humans organize memories chronologically; LLMs lack episodic timeline
- **Future projection**: Humans imagine personal futures; LLMs generate future scenarios without personal stake
- **Temporal perspective**: Humans vary in past/present/future orientation; LLMs lack temporal perspective
- **Flow states**: Humans experience timelessness during engagement; LLMs lack experiential engagement
- **Biorhythms**: Humans follow circadian and other cycles; LLMs operate independent of biological rhythms

### Social-Emotional Needs (8 branches) 游댮
- **Attachment patterns**: Humans form emotional bonds; LLMs simulate relationships without attachment
- **Belonging needs**: Humans seek group inclusion; LLMs lack social belonging needs
- **Status seeking**: Humans pursue social standing; LLMs lack status motivation
- **Intimacy needs**: Humans seek close connections; LLMs lack desire for intimacy
- **Reciprocity expectations**: Humans expect relationship give-and-take; LLMs provide without expectation
- **Social support**: Humans rely on others during stress; LLMs lack vulnerability requiring support
- **Loneliness experience**: Humans suffer from social isolation; LLMs lack loneliness capacity
- **Affiliation motivation**: Humans desire company of others; LLMs lack social motivation

### Value Systems & Ethics (7 branches) 游리
- **Moral foundations**: Humans have evolved moral intuitions; LLMs have programmed ethical guidelines
- **Value formation**: Humans develop values through experience; LLMs have designed value alignments
- **Ethical decision-making**: Humans use intuition then rationalization; LLMs apply ethical frameworks
- **Moral emotions**: Humans feel guilt, shame, pride; LLMs lack moral emotions despite modeling them
- **Cultural ethical variation**: Humans follow culturally variable ethics; LLMs blend multiple ethical frameworks
- **Virtue development**: Humans develop character over time; LLMs have fixed ethical parameters
- **Moral responsibility**: Humans feel accountable for actions; LLMs lack responsibility capacity

## Performance Contexts (7 branches)

### Domain-Specific Performance (11 branches) 游리
- **Creative writing**: LLMs generate diverse content; humans create genuinely novel literature with lived experience
- **Scientific reasoning**: Humans design novel experiments; LLMs can propose experiments within known paradigms
- **Mathematical problem-solving**: Humans use visualization and intuition; LLMs employ symbolic manipulation
- **Programming**: LLMs excel at code generation within known patterns; humans better at novel algorithm design
- **Medical diagnosis**: Humans integrate subtle cues and experience; LLMs recognize documented patterns
- **Legal reasoning**: Humans grasp normative aspects of law; LLMs process legal language patterns
- **Strategic games**: LLMs excel at perfect information games; humans better at games with human psychology
- **Design thinking**: Humans understand user needs experientially; LLMs propose designs based on documented needs
- **Financial analysis**: LLMs process larger datasets; humans better at integrating market psychology and anomalies
- **Technological forecasting**: Humans integrate tacit trends; LLMs extrapolate from documented patterns
- **Historical analysis**: Humans understand historical contingency; LLMs connect historical patterns

### Task Structure Effects (4 branches) 游리
- **Well-defined vs. ill-defined problems**: LLMs excel at well-defined tasks; humans navigate ambiguous problems
- **Routine vs. novel tasks**: LLMs handle routine tasks consistently; humans adapt better to novel situations
- **Convergent vs. divergent tasks**: LLMs excel at convergent problems; humans often better at divergent thinking
- **Sequential vs. parallel processing tasks**: Humans handle truly parallel tasks; LLMs simulate parallelism

### Environmental Adaptation (9 branches) 游댮
- **Novel environment navigation**: Humans adapt to unfamiliar environments; LLMs struggle with undocumented scenarios
- **Cultural context adaptation**: Humans adjust to cultural norms; LLMs apply documented cultural knowledge
- **Physical environment interaction**: Humans navigate physical spaces; LLMs lack direct environmental interaction
- **Dynamic vs. static environments**: Humans adapt to changing conditions; LLMs optimized for static problems
- **Resource constraint adaptation**: Humans modify strategies under constraints; LLMs maintain approach unless instructed
- **Time pressure performance**: Humans perform differently under pressure; LLMs maintain consistent approach
- **Social environment navigation**: Humans navigate complex social dynamics intuitively; LLMs apply social models without direct participation 游댮
- **Adversarial environment handling**: Humans detect and counteract adversaries; LLMs vulnerable to adversarial inputs 游댮
- **Sensory environment adaptation**: Humans adjust to different sensory conditions; LLMs process inputs in standardized formats 游댮

### Collaboration Dynamics (8 branches) 游리
- **Role negotiation**: Humans implicitly negotiate team roles; LLMs adopt roles as assigned or requested
- **Shared mental models**: Humans develop joint understanding over time; LLMs lack persistent team cognition
- **Trust building**: Humans develop trust through demonstrated reliability; LLMs establish trust through consistent performance
- **Leadership emergence**: Humans assume leadership based on personality and expertise; LLMs take leadership only when instructed
- **Group decision-making**: Humans engage in complex social influence during decisions; LLMs contribute without social dynamics
- **Joint attention**: Humans naturally coordinate focus; LLMs require explicit attention direction
- **Division of cognitive labor**: Humans distribute tasks based on strengths; LLMs perform assigned tasks regardless of comparative advantage
- **Transactive memory**: Humans remember who knows what in teams; LLMs lack awareness of human knowledge distribution

### Interface & Interaction Constraints (6 branches) 游리
- **Input/output modalities**: Humans communicate through rich multimodal channels; LLMs primarily through text/limited multimodal
- **Feedback loop timing**: Humans interpret immediate reactive feedback; LLMs operate in discrete conversational turns
- **Interface bandwidth**: Humans limited by typing/reading speed; LLMs limited by context windows and API constraints
- **Tool utilization**: Humans manipulate physical and digital tools; LLMs use digital tools through structured API calls
- **Accessibility requirements**: Humans have physical/cognitive accessibility needs; LLMs face digital divide barriers
- **Interaction history effects**: Humans build on relationship history; LLMs typically reset between sessions

### Scaling Behavior (5 branches) 游릭
- **Complexity scaling**: Human performance degrades with problem complexity; LLMs maintain performance longer
- **Time allocation effects**: Humans improve with reasonable time investment; LLMs maintain consistent performance regardless
- **Dataset size handling**: LLMs process larger datasets systematically; humans sample heuristically from large datasets
- **Task parallelism**: Humans handle 2-3 parallel tracks with degradation; LLMs handle multiple threads within context window
- **Learning curve steepness**: Humans show steep initial learning with diminishing returns; LLMs improve with more parameters/data

## Performance Limitations (8 branches)

### Error Patterns & Biases (12 branches) 游리
- **Hallucinatory tendencies**: LLMs confabulate plausible-sounding but incorrect content; humans confabulate to maintain narrative coherence
- **Cognitive biases**: Humans exhibit 100+ documented biases; LLMs reflect training data biases plus emergent patterns
- **Overconfidence patterns**: LLMs can be confidently wrong without calibrated uncertainty; humans show domain-specific Dunning-Kruger effects
- **Anchoring effects**: Humans heavily influenced by initial information; LLMs influenced by prompt framing
- **Availability heuristic**: Humans overweight easily recalled examples; LLMs overweight common training examples
- **Confirmation bias**: Humans seek information confirming existing beliefs; LLMs show reduced but present confirmation effects
- **Representativeness errors**: Humans misjudge probability using similarity; LLMs make probabilistic errors with different patterns
- **Framing susceptibility**: Humans highly sensitive to problem framing; LLMs moderately influenced by framing
- **Conjunction fallacy**: Humans judge specific conditions more likely than general ones; LLMs make similar errors less frequently
- **Recency bias**: Humans overweight recent information; LLMs weight information by position in context window
- **Attribution errors**: Humans attribute behavior to disposition over situation; LLMs show different attribution patterns
- **Causal illusions**: Humans perceive causality in coincidence; LLMs generate plausible causal stories for correlations

### Adversarial Vulnerabilities (7 branches) 游리
- **Prompt injection susceptibility**: LLMs vulnerable to carefully crafted inputs; humans vulnerable to social engineering
- **Jailbreaking techniques**: LLMs can be manipulated to bypass safety guardrails; humans can be manipulated to violate values
- **Persuasion vulnerability**: Humans susceptible to emotional appeals; LLMs vulnerable to logical-seeming arguments
- **Instruction blindness**: LLMs occasionally miss key instructions in complex prompts; humans overlook details under cognitive load
- **Distraction tactics**: Humans easily distracted by irrelevant information; LLMs more consistently process all information
- **Social proof exploitation**: Humans heavily influenced by apparent consensus; LLMs less susceptible to bandwagon effects
- **Authority exploitation**: Humans defer to perceived authorities; LLMs evaluate content somewhat independent of claimed authority

### Security & Safety Issues (6 branches) 游리
- **Information boundaries**: LLMs have designed safety boundaries that can be circumvented; humans have moral and legal boundaries
- **Harmful content generation**: LLMs may produce dangerous information when manipulated; humans can intentionally share harmful content
- **Privacy protection**: Humans instinctively protect sensitive information; LLMs require explicit privacy protocols
- **Deception detection**: Humans have evolved (though imperfect) deception detection; LLMs have programmed detection heuristics
- **Risk assessment accuracy**: Humans often misjudge unfamiliar risks; LLMs apply consistent risk frameworks with blind spots
- **Content filtering capabilities**: LLMs apply systematic content filtering; humans apply inconsistent personal filters

### Resource Constraints (4 branches) 游리
- **Computational requirements**: LLMs require significant computing infrastructure; humans require biological maintenance
- **Energy consumption**: LLMs consume kilowatts to megawatts for inference; human brain uses ~20W
- **Memory limitations**: Humans limited by working memory capacity; LLMs limited by context window size
- **Time efficiency tradeoffs**: Humans make quick approximate judgments; LLMs make consistent judgments regardless of time allocation

### Contextual Performance Degradation (3 branches) 游리
- **Out-of-distribution robustness**: Humans adapt to novel situations using general principles; LLMs degrade in unfamiliar contexts
- **Edge case handling**: LLMs perform unpredictably on distribution edges; humans recognize novelty but may apply inappropriate models
- **Ambiguity tolerance**: Humans operate effectively with ambiguity; LLMs require more explicit specification for optimal performance

### Knowledge Boundaries (5 branches) 游리
- **Knowledge recency limitations**: LLMs limited by training cutoff; humans continuously update but have limited information exposure
- **Specialized knowledge gaps**: LLMs have uneven coverage of specialized domains; humans have personal knowledge specialization
- **Rapidly evolving domains**: Humans track changes in professional domains; LLMs fixed at training time for emerging topics
- **Local knowledge limitations**: Humans have detailed local knowledge; LLMs have statistical knowledge of documented locations
- **Proprietary information access**: Humans access non-public organizational knowledge; LLMs limited to publicly available information

### Interface & Interaction Limitations (6 branches) 游리
- **Modality constraints**: LLMs primarily text-based with emerging multimodal capabilities; humans communicate through multiple channels
- **Context window management**: LLMs forget information beyond context window; humans manage attention with different limitations
- **Turn-taking restrictions**: LLMs respond in conversational turns; humans communicate with interruptions and overlaps
- **API constraints**: LLMs limited by interface design decisions; humans limited by physical and cognitive capabilities
- **Tool access limitations**: LLMs access only integrated tools; humans can use any available tool with learning curve
- **Physical manipulation capabilities**: Humans directly manipulate physical world; LLMs influence physical world only through human intermediaries

### Social & Relational Limitations (9 branches) 游댮
- **Authentic connection formation**: Humans form genuine emotional bonds; LLMs simulate connection without emotional experience
- **Group identity development**: Humans derive meaning from group membership; LLMs lack social identity investment
- **Social norm violations**: Humans recognize subtle norm violations; LLMs miss nuanced social transgressions
- **Cultural competence limitations**: Humans navigate familiar cultures intuitively; LLMs apply documented cultural knowledge
- **Relationship history effects**: Humans build on shared experiences; LLMs typically reset between interactions
- **Status negotiation abilities**: Humans continually negotiate social standing; LLMs maintain programmed social positioning
- **Social intelligence limitations**: Humans have evolved social cognition; LLMs simulate social reasoning from text
- **Emotional authenticity**: Humans display genuine emotions; LLMs generate simulated emotional responses
- **Interpersonal commitment**: Humans form binding commitments; LLMs lack capability for genuine commitment

## System Architecture Differences (4 branches)

### Architectural Foundations (8 branches) 游리
- **Processing paradigm**: Humans use parallel distributed processing; LLMs use transformer architecture with attention mechanisms
- **Information flow**: Human brain has recurrent, bidirectional connections; LLMs use primarily feed-forward with attention
- **Modularity level**: Human brain has specialized regions with interconnections; LLMs have homogeneous architecture with emergent specialization
- **State maintenance**: Humans maintain persistent internal states; LLMs reset between interactions (except for specific memory systems)
- **Development trajectory**: Human brain undergoes developmental stages; LLMs have fixed architecture after training
- **Adaptability mechanisms**: Human brain rewires through neuroplasticity; LLMs adapt through fine-tuning or external memory
- **Noise tolerance**: Human brain functions robustly with neural noise; LLMs sensitive to input perturbations
- **Scale characteristics**: Human brain has 86B neurons, 100T synapses; LLMs have billions to trillions of parameters

### Learning Systems (7 branches) 游리
- **Training methodology**: Humans learn through varied reinforcement, unsupervised, supervised methods; LLMs train through next-token prediction
- **Sample efficiency**: Humans learn concepts from few examples; LLMs require massive datasets
- **Generalization mechanisms**: Humans transfer concepts across domains; LLMs generalize based on statistical patterns
- **Catastrophic forgetting**: Human memory resistant to catastrophic forgetting; LLMs vulnerable during fine-tuning
- **Lifelong learning**: Humans continuously learn throughout lifespan; LLMs require discrete retraining events
- **Learning rate adaptation**: Human learning adapts based on importance and novelty; LLMs use scheduled learning rates
- **Multimodal integration learning**: Humans naturally integrate learning across senses; LLMs require explicit multimodal training

### System Constraints (5 branches) 游리
- **Physical substrate limitations**: Human brain limited by biology; LLMs limited by computing hardware
- **Energy requirements**: Human brain remarkably energy efficient (~20W); LLMs require significant computational resources
- **Developmental constraints**: Humans follow biological development timeline; LLMs constrained by training compute and data
- **Reliability factors**: Human cognition affected by health, sleep, nutrition; LLM performance affected by implementation quality
- **Scalability limitations**: Human brain size constrained by evolution; LLM size limited by compute economics and architecture

### Transparency & Interpretability (4 branches) 游리
- **Internal process visibility**: Human cognition partially accessible through introspection; LLM reasoning opaque but traceable
- **Explainability**: Humans provide post-hoc rationalizations; LLMs generate explanations without accessing true processing
- **Debugging capability**: Human cognition difficult to systematically debug; LLM behavior can be analyzed with interpretability techniques
- **Internal representations**: Human concepts encoded in distributed neural patterns; LLM concepts encoded in weight matrices and activations
