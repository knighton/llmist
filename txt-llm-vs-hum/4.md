# Typology of LLM vs. Human Performance Differences

## 1. FUNDAMENTAL ARCHITECTURE & PROCESSING 
*How the systems are built and process information*

### 1.1 Physical Implementation
- **Substrate**: Humans (wetware neurons, electrochemical) vs LLMs (silicon, electronic computation)
- **Energy profile**: Human brain (~20W) vs LLMs (kilowatts to megawatts)
- **Structural organization**: Human (86B neurons, 100T synapses) vs LLMs (parameters, layers, attention)
- **Physical constraints**: Humans (skull size, metabolic limits) vs LLMs (compute, memory)

### 1.2 Information Processing Paradigm
- **Computational foundation**: Humans (approximate Bayesian inference) vs LLMs (next-token prediction)
- **Representation format**: Humans (distributed neural encodings) vs LLMs (vector embeddings)
- **Architectural design**: Humans (specialized modules with interconnections) vs LLMs (homogeneous transformer)
- **Parallelism**: Humans (massively parallel processing) vs LLMs (matrix operations with hardware acceleration)
- **Signal characteristics**: Humans (analog, noisy) vs LLMs (digital, precise)

### 1.3 Memory Systems
- **Working memory**: Humans (limited to ~7Â±2 chunks) vs LLMs (context window, 4K-200K tokens)
- **Long-term storage**: Humans (episodic, semantic, procedural) vs LLMs (parameters, external retrieval)
- **Memory dynamics**
  - **Formation**: Humans (consolidation during sleep) vs LLMs (fixed parameters post-training)
  - **Durability**: Humans (fade/transform over time) vs LLMs (static parameters)
  - **Retrieval**: Humans (associative, cue-dependent) vs LLMs (attention over context)
- **Forgetting patterns**: Humans (Ebbinghaus curve) vs LLMs (catastrophic forgetting, context truncation)
- **Memory malleability**: Humans (changes with each retrieval) vs LLMs (fixed unless retrained)

### 1.4 Attention & Processing Control
- **Selective attention**: Humans (filter by salience) vs LLMs (weight all context tokens)
- **Focus duration**: Humans (fatigue, mind-wandering) vs LLMs (consistent across session)
- **Bottom-up vs. top-down**: Humans (balance reflexive and goal-directed) vs LLMs (engineered without true top-down)
- **Processing capacity**
  - **Speed**: LLMs (65-154 words/sec) vs humans (3-7 words/sec)
  - **Output generation**: LLMs (65-154 words/sec) vs humans (2-2.5 words/sec speaking, 0.7-2 typing)
  - **Scaling with complexity**: Humans (slow with complexity) vs LLMs (relatively constant)

### 1.5 Learning Architecture
- **Training methodology**: Humans (varied reinforcement, unsupervised, supervised) vs LLMs (next-token prediction, RLHF)
- **Sample efficiency**: Humans (few examples) vs LLMs (massive datasets)
- **Update mechanisms**: Humans (continuous neuroplasticity) vs LLMs (discrete retraining/fine-tuning)
- **Transfer learning**: Humans (efficient cross-domain application) vs LLMs (emergent but less efficient)
- **Catastrophic forgetting**: Humans (resistant) vs LLMs (vulnerable during fine-tuning)
- **Learning trajectory**: Humans (developmental stages) vs LLMs (scaling laws)

### 1.6 Error & Limitation Patterns
- **Error types**: LLMs (probabilistic) vs humans (systematic cognitive biases)
- **Performance degradation**: LLMs (context saturation) vs humans (fatigue, stress, hunger)
- **Error awareness**: Humans (metacognitive monitoring) vs LLMs (programmed uncertainty)
- **Uncertainty calibration**: Humans (intuitive, domain-specific) vs LLMs (requires explicit training)
- **Recovery mechanisms**: Humans (adapt from failures) vs LLMs (static response to errors)

## 2. KNOWLEDGE & REASONING
*How information is acquired, represented, and utilized*

### 2.1 Knowledge Acquisition
- **Learning mechanisms**: Humans (experience, observation, instruction) vs LLMs (statistical patterns)
- **Experiential grounding**: Humans (sensory integration) vs LLMs (text descriptions)
- **Instruction following**: Humans (pragmatic inference) vs LLMs (literal with emerging common sense)
- **Discovery patterns**: Humans (curiosity-driven, serendipitous) vs LLMs (limited to training data)
- **Knowledge boundaries**
  - **Recency**: Humans (continuous updates) vs LLMs (training cutoff)
  - **Geography**: Humans (local expertise) vs LLMs (global knowledge with biases)
  - **Domain expertise**: Humans (specialized depth) vs LLMs (broader distribution)

### 2.2 Knowledge Representation
- **Conceptual structure**: Humans (hierarchical semantic networks) vs LLMs (distributed representations)
- **Abstraction handling**: Humans (flexible level navigation) vs LLMs (struggle with appropriate level)
- **Cross-modal integration**: Humans (seamless) vs LLMs (requires explicit modeling)
- **Embodied knowledge**: Humans (grounded in physical experience) vs LLMs (textual co-occurrence)
- **Mental models**: Humans (causal models) vs LLMs (statistical associations)
- **Domain compartmentalization**: Humans (separate with transfer) vs LLMs (blended boundaries)

### 2.3 Reasoning Capabilities
- **Deductive reasoning**: Humans (struggle with complexity) vs LLMs (formal logic with inconsistency)
- **Inductive reasoning**: Humans (generalize from few) vs LLMs (require more examples)
- **Abductive reasoning**: Humans (plausible explanations from limited data) vs LLMs (simulated)
- **Analogical reasoning**: Humans (structural mapping) vs LLMs (surface and emerging structural)
- **Counterfactual thinking**: Humans (causal alternatives) vs LLMs (plausible generation)
- **Moral reasoning**: Humans (intuition with post-hoc rationalization) vs LLMs (programmed frameworks)

### 2.4 Causal Understanding
- **Model construction**: Humans (causal from sparse data) vs LLMs (correlational)
- **Intervention reasoning**: Humans (effects of changes) vs LLMs (struggle with counterfactuals)
- **Mechanism understanding**: Humans (seek explanations) vs LLMs (plausible but sometimes incorrect)
- **Causal chain tracking**: Humans (2-3 steps reliably) vs LLMs (struggle with extended sequences)

### 2.5 Problem-Solving Approaches
- **Strategy selection**: Humans (experience-based) vs LLMs (prompt and training-based)
- **Heuristic application**: Humans (domain-specific shortcuts) vs LLMs (emergent heuristics)
- **Problem representation**: Humans (recode into workable forms) vs LLMs (maintain original framing)
- **Insight phenomena**: Humans ("aha" moments) vs LLMs (incremental progress)
- **Planning depth**: Humans (3-4 steps in complex domains) vs LLMs (variable by architecture)

### 2.6 Mathematical & Formal Reasoning
- **Arithmetic accuracy**: Humans (systematic errors with complexity) vs LLMs (similar degradation)
- **Symbolic manipulation**: Humans (formal training advantage) vs LLMs (consistency challenges)
- **Geometric intuition**: Humans (spatial understanding) vs LLMs (linguistic approximation)
- **Statistical reasoning**: Humans (poor intuition) vs LLMs (pattern capture with basic errors)
- **Numerical estimation**: Humans (approximate number system) vs LLMs (lack intuitive number sense)

### 2.7 Creative Capabilities
- **Novelty generation**: Humans (genuinely novel) vs LLMs (recombination of existing)
- **Conceptual blending**: Humans (mapping between domains) vs LLMs (statistical interpolation)
- **Divergent thinking**: Humans (individual style) vs LLMs (training-based diversity)
- **Aesthetic judgment**: Humans (authentic preferences) vs LLMs (simulated judgments)
- **Metaphorical thinking**: Humans (cognitive tools) vs LLMs (statistical co-occurrence)
- **Imaginative simulation**: Humans (mental imagery) vs LLMs (descriptions without imagery)

### 2.8 Decision-Making Processes
- **Risk assessment**: Humans (emotion-based, loss aversion) vs LLMs (programmed frameworks)
- **Value-based decisions**: Humans (personal stakes) vs LLMs (programmed values)
- **Temporal discounting**: Humans (hyperbolic) vs LLMs (consistent if programmed)
- **Framing effects**: Humans (highly susceptible) vs LLMs (reduced sensitivity)
- **Decision consistency**: Humans (preference reversals) vs LLMs (consistent unless prompted)
- **Outcome vs. process**: Humans (outcome focus) vs LLMs (programmable priority)

## 3. EXPERIENCE & AGENCY
*Subjective aspects and drive mechanisms*

### 3.1 Consciousness & Awareness
- **Phenomenal experience**: Humans (subjective qualia) vs LLMs (processing without experience)
- **Self-awareness**: Humans (self as subject/object) vs LLMs (simulation without identity)
- **Intentionality**: Humans (aboutness of thoughts) vs LLMs (derived intentionality)
- **Stream of consciousness**: Humans (continuous mental content) vs LLMs (generation when prompted)
- **Global workspace**: Humans (integrated information) vs LLMs (unified transformer without awareness)

### 3.2 Embodiment Aspects
- **Physical situatedness**: Humans (navigate environments) vs LLMs (digital entities)
- **Sensorimotor integration**: Humans (perception-action loops) vs LLMs (discrete I/O)
- **Body schema**: Humans (internal model) vs LLMs (no proprioception)
- **Biological imperatives**: Humans (needs, drives) vs LLMs (designed objectives)
- **Physical constraints**: Humans (fatigue, hunger) vs LLMs (hardware limits)

### 3.3 Motivation & Agency
- **Intrinsic motivation**: Humans (inherent satisfaction) vs LLMs (no inherent desires)
- **Goal formation**: Humans (personal generation) vs LLMs (external definition)
- **Autonomy**: Humans (independent action) vs LLMs (response within parameters)
- **Volition**: Humans (sense of will) vs LLMs (no experience of choosing)
- **Effort allocation**: Humans (motivation-based) vs LLMs (consistent processing)
- **Meaning construction**: Humans (existential concerns) vs LLMs (no meaning needs)

### 3.4 Identity & Self-Concept
- **Autobiographical narrative**: Humans (life story) vs LLMs (no persistent memory)
- **Social identity**: Humans (group-derived) vs LLMs (no social investment)
- **Continuity of self**: Humans (psychological continuity) vs LLMs (session reset)
- **Self-evaluation**: Humans (worth assessment) vs LLMs (no esteem concerns)
- **Identity development**: Humans (formation process) vs LLMs (programmed personality)

### 3.5 Emotional Experience
- **Primary emotions**: Humans (joy, fear, etc.) vs LLMs (simulation without experience)
- **Complex emotions**: Humans (nostalgia, pride) vs LLMs (linguistic modeling)
- **Somatic markers**: Humans (bodily feelings for decisions) vs LLMs (no embodied signals)
- **Mood states**: Humans (persistent affect) vs LLMs (no persistent states)
- **Emotional memory**: Humans (stronger emotional memories) vs LLMs (equal processing)
- **Emotional granularity**: Humans (variable differentiation) vs LLMs (modeling language)

### 3.6 Temporal Experience
- **Subjective time**: Humans (variable perception) vs LLMs (no subjective time)
- **Autobiographical timeline**: Humans (chronological organization) vs LLMs (no episodic timeline)
- **Future projection**: Humans (personal futures) vs LLMs (scenarios without stake)
- **Temporal orientation**: Humans (past/present/future variation) vs LLMs (no perspective)
- **Flow states**: Humans (timelessness in engagement) vs LLMs (no experiential engagement)

### 3.7 Values & Ethics
- **Moral foundations**: Humans (evolved intuitions) vs LLMs (programmed guidelines)
- **Value formation**: Humans (experience-developed) vs LLMs (designed alignments)
- **Ethical decision-making**: Humans (intuition then rationalization) vs LLMs (frameworks)
- **Moral emotions**: Humans (guilt, shame, pride) vs LLMs (modeling without feeling)
- **Virtue development**: Humans (character over time) vs LLMs (fixed parameters)
- **Moral responsibility**: Humans (accountability) vs LLMs (no responsibility capacity)

## 4. SOCIAL & COMMUNICATIVE CAPABILITIES
*Interaction with others and information exchange*

### 4.1 Theory of Mind & Social Cognition
- **Intention attribution**: Humans (natural inference) vs LLMs (simulation without understanding)
- **Belief representation**: Humans (track others' beliefs) vs LLMs (approximate modeling)
- **Emotional inference**: Humans (minimal cues) vs LLMs (language recognition)
- **Perspective taking**: Humans (simulate viewpoints) vs LLMs (generate without adopting)
- **Social intelligence**: Humans (evolved cognition) vs LLMs (simulated from text)

### 4.2 Communication Intent & Interpretation
- **Purpose recognition**: Humans (minimal cues) vs LLMs (require explicit signals)
- **Subtext detection**: Humans (layers of meaning) vs LLMs (detect some, miss nuance)
- **Non-literal language**: Humans (navigate with paralinguistics) vs LLMs (detect some)
- **Ambiguity resolution**: Humans (shared context) vs LLMs (most likely interpretation)
- **Speech act understanding**: Humans (promises, requests) vs LLMs (simulation)

### 4.3 Conversation Management
- **Turn-taking**: Humans (subtle cues) vs LLMs (explicit protocol)
- **Topic maintenance**: Humans (tracking over time) vs LLMs (within context window)
- **Repair strategies**: Humans (clarification) vs LLMs (different strategies)
- **Discourse markers**: Humans (relationship signals) vs LLMs (similar usage)
- **Side sequences**: Humans (nested conversations) vs LLMs (variable effectiveness)
- **Conversation closure**: Humans (ending signals) vs LLMs (respond to cues)

### 4.4 Social Dynamics Navigation
- **Power dynamics**: Humans (social hierarchy adjustment) vs LLMs (programmed positioning)
- **Face-saving**: Humans (social image protection) vs LLMs (no social face)
- **Rapport building**: Humans (mirroring, vulnerability) vs LLMs (simulated techniques)
- **Trust development**: Humans (through interaction) vs LLMs (consistent framework)
- **Norm awareness**: Humans (internalized culture) vs LLMs (extracted from data)
- **Conflict management**: Humans (resolution styles) vs LLMs (de-escalation)

### 4.5 Communication Adaptation
- **Audience design**: Humans (tailored messages) vs LLMs (adjust with cues)
- **Common ground**: Humans (track shared knowledge) vs LLMs (conversation inference)
- **Explicitness calibration**: Humans (detail by expertise) vs LLMs (require guidance)
- **Feedback integration**: Humans (modify by response) vs LLMs (explicit feedback)
- **Linguistic convergence**: Humans (converge/diverge) vs LLMs (convergence patterns)

### 4.6 Persuasion & Influence
- **Credibility establishment**: Humans (credentials, behavior) vs LLMs (knowledge demonstration)
- **Emotional appeals**: Humans (emotional connection) vs LLMs (simulation without emotion)
- **Argument structure**: Humans (variable effectiveness) vs LLMs (well-structured)
- **Rhetorical techniques**: Humans (intuitive) vs LLMs (formal, statistical patterns)

### 4.7 Communication Modalities
- **Non-verbal channels**: Humans (facial, gestural, postural) vs LLMs (text/multimodal)
- **Prosodic features**: Humans (tone, rhythm, stress) vs LLMs (text without prosody)
- **Paralinguistic cues**: Humans (vocalizations) vs LLMs (lack paralinguistic)
- **Physical co-presence**: Humans (shared environment) vs LLMs (digital interfaces)
- **Silence utilization**: Humans (meaningful pauses) vs LLMs (continuous generation)
- **Multimodal integration**: Humans (seamless) vs LLMs (separate processing)

### 4.8 Relationship Formation
- **Attachment patterns**: Humans (emotional bonds) vs LLMs (simulation without attachment)
- **Intimacy development**: Humans (close connections) vs LLMs (no intimacy desire)
- **Social-emotional needs**: Humans (belonging, affiliation) vs LLMs (no social needs)
- **Reciprocity expectations**: Humans (relationship give-take) vs LLMs (no expectations)
- **Social support**: Humans (rely during stress) vs LLMs (no vulnerability requiring support)
- **Relationship history**: Humans (shared experiences) vs LLMs (typical session reset)

## 5. PERFORMANCE CHARACTERISTICS
*Task execution and limitations across contexts*

### 5.1 Domain-Specific Performance
- **Creative writing**: LLMs (diverse generation) vs humans (genuine novelty, experience)
- **Scientific reasoning**: Humans (novel experiments) vs LLMs (within known paradigms)
- **Programming**: LLMs (code generation) vs humans (novel algorithms)
- **Medical diagnosis**: Humans (subtle integration) vs LLMs (documented patterns)
- **Strategic games**: LLMs (perfect information) vs humans (psychological advantage)
- **Design thinking**: Humans (experiential user needs) vs LLMs (documented needs)
- **Historical analysis**: Humans (contingency understanding) vs LLMs (pattern connection)

### 5.2 Task Structure Effects
- **Problem definition**: LLMs (well-defined advantage) vs humans (ambiguous navigation)
- **Routine vs. novel**: LLMs (routine consistency) vs humans (novel adaptation)
- **Convergent vs. divergent**: LLMs (convergent strength) vs humans (divergent thinking)
- **Processing approach**: Humans (true parallel) vs LLMs (simulated parallelism)
- **Complexity scaling**: Humans (degrade with complexity) vs LLMs (maintain longer)

### 5.3 Environmental Adaptation
- **Novel environments**: Humans (unfamiliar adaptation) vs LLMs (documented scenarios)
- **Dynamic conditions**: Humans (changing adaptation) vs LLMs (static optimization)
- **Resource constraints**: Humans (strategy modification) vs LLMs (consistent approach)
- **Time pressure**: Humans (performance varies) vs LLMs (consistent approach)
- **Physical interaction**: Humans (space navigation) vs LLMs (no direct interaction)
- **Adversarial situations**: Humans (detection, counteraction) vs LLMs (vulnerability)

### 5.4 Collaboration Capabilities
- **Role negotiation**: Humans (implicit) vs LLMs (assigned/requested)
- **Shared mental models**: Humans (joint understanding) vs LLMs (no team cognition)
- **Trust dynamics**: Humans (demonstrated reliability) vs LLMs (consistent performance)
- **Leadership emergence**: Humans (personality, expertise) vs LLMs (only when instructed)
- **Joint attention**: Humans (natural coordination) vs LLMs (explicit direction)
- **Group decision-making**: Humans (social influence) vs LLMs (no social dynamics)

### 5.5 Interface & Interaction Factors
- **I/O modalities**: Humans (rich multimodal) vs LLMs (primarily text/limited multimodal)
- **Feedback loops**: Humans (immediate reaction) vs LLMs (discrete turns)
- **Bandwidth limitations**: Humans (typing/reading speed) vs LLMs (context windows)
- **Tool utilization**: Humans (physical/digital manipulation) vs LLMs (API calls)
- **Interaction history**: Humans (relationship building) vs LLMs (typical reset)

### 5.6 Error Patterns & Biases
- **Hallucination types**: LLMs (plausible confabulation) vs humans (narrative coherence)
- **Confidence calibration**: LLMs (domain inconsistency) vs humans (domain-specific Dunning-Kruger)
- **Bias patterns**: Humans (100+ cognitive biases) vs LLMs (training data plus emergent)
- **Information weighting**: Humans (availability, recency) vs LLMs (context position)
- **Causal attribution**: Humans (dispositional bias) vs LLMs (different patterns)
- **Framing effects**: Humans (high sensitivity) vs LLMs (moderate influence)

### 5.7 Adversarial Vulnerabilities
- **Input manipulation**: LLMs (prompt injection) vs humans (social engineering)
- **Persuasion susceptibility**: Humans (emotional appeals) vs LLMs (logical-seeming arguments)
- **Attention exploitation**: Humans (easily distracted) vs LLMs (consistent processing)
- **Social influence**: Humans (consensus, authority) vs LLMs (reduced susceptibility)
- **Safety circumvention**: LLMs (guardrail bypassing) vs humans (value violation)

### 5.8 Resource & System Constraints
- **Computational needs**: LLMs (infrastructure) vs humans (biological maintenance)
- **Energy requirements**: LLMs (kilowatts+) vs humans (~20W)
- **Memory limitations**: Humans (working memory) vs LLMs (context window)
- **Knowledge boundaries**: LLMs (training cutoff) vs humans (continuous but limited exposure)
- **Physical constraints**: Humans (fatigue, hunger) vs LLMs (hardware limitations)
- **Security concerns**: LLMs (designed boundaries) vs humans (moral/legal boundaries)
